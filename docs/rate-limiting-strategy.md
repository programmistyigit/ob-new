# Telegram Rate Limiting & IP Blocking Prevention

## âš ï¸ Xavf: IP va Account Bloklash

### **Ha, IP bloklanishi mumkin agar:**

1. **Juda ko'p requestlar** - 30+ message/minute bitta accountdan
2. **Juda ko'p connectionlar** - Bir IP dan ko'p transport connection
3. **Flood Wait ignore qilish** - Error ni e'tiborsiz qoldirish
4. **Yangi accountlar** - Temp SMS dan olingan accountlar tezroq bloklanadi

---

## ğŸ“Š Telegram Rate Limits (2025)

### **Bot API Limits:**
```
âœ… ~30 messages/second turli userlarga
âœ… 1 message/second bitta chatga
âœ… 20 messages/minute bitta guruhga
âœ… 100 concurrent connections max

âš ï¸ Limit BOT_TOKEN ga bog'liq, IP ga emas
```

### **User API (MTProto - Userbot) Limits:**
```
âš ï¸ ~30 messages/minute - xavfsiz chegara
âš ï¸ 40-50 messages - SLOW_MODE boshlanadi
âš ï¸ 50+ messages - FLOOD_WAIT_ERROR (majburiy kutish)

ğŸ”´ Error 429 (Transport Flood) - IP level block!
   - Juda ko'p transport connection bir IPdan
   - Barcha accountlar bloklanadi
```

### **Account Age Factor:**
```
ğŸ†• Yangi account (temp SMS): ~5 message keyin limit
ğŸ“… Aged account (2+ yil): Oylab ishlaydi
ğŸ’ Premium + Aged: Eng ko'p limit (recommended!)
```

---

## ğŸš¨ Error Codes

| Error | Code | Ma'nosi | Javob |
|-------|------|---------|--------|
| `FLOOD_WAIT_X` | 420 | X sekund kutish | Sleep X sekund, keyin retry |
| `Too Many Requests` | 429 | **IP-level limit!** | Barcha activityni to'xtat |
| `SLOW_MODE` | - | Sekinlashtirilgan | Delay oshir |

### **Penalty Scale:**
```
1-chi marta: 60-300 sekund
Takroriy: 70,000+ sekund (~19 soat!)
Severe: Temporary IP/account ban
```

---

## âœ… OblivionLog uchun Prevention Strategy

### **1. Request Queue System (RECOMMENDED)**

Har bir userbot uchun queue:

```typescript
// src/userbot/rateLimiter.ts
import PQueue from 'p-queue';

const queueMap = new Map<number, PQueue>();

export function getUserQueue(userId: number): PQueue {
  if (!queueMap.has(userId)) {
    queueMap.set(userId, new PQueue({
      interval: 60000,      // 1 minute
      intervalCap: 25,      // Max 25 requests/minute (safe margin)
      concurrency: 1,       // One at a time
    }));
  }
  return queueMap.get(userId)!;
}

export async function queuedRequest<T>(
  userId: number, 
  fn: () => Promise<T>
): Promise<T> {
  const queue = getUserQueue(userId);
  return queue.add(fn);
}
```

### **2. Flood Wait Handler**

```typescript
// src/utils/floodWaitHandler.ts
import { createLogger } from './logger';

const logger = createLogger('FloodWaitHandler');

export async function handleFloodWait<T>(
  fn: () => Promise<T>,
  maxRetries: number = 3
): Promise<T | null> {
  let retries = 0;
  
  while (retries < maxRetries) {
    try {
      return await fn();
    } catch (error: any) {
      if (error.message?.includes('FLOOD_WAIT')) {
        const waitMatch = error.message.match(/FLOOD_WAIT_(\\d+)/);
        if (waitMatch) {
          const waitTime = parseInt(waitMatch[1]);
          logger.warn({ waitTime, retries }, 'FLOOD_WAIT detected, sleeping');
          
          // Sleep + 10% buffer
          await new Promise(resolve => setTimeout(resolve, (waitTime + 5) * 1000));
          retries++;
          continue;
        }
      }
      
      if (error.code === 429) {
        logger.error('ERROR 429: IP-level block! Stopping all activity.');
        throw new Error('IP_BLOCKED: Stop all clients immediately!');
      }
      
      throw error;
    }
  }
  
  logger.error('Max retries reached for FLOOD_WAIT');
  return null;
}
```

### **3. Message Sending with Queue**

```typescript
// src/userbot/archiveHandler.ts (yangilash kerak)

import { queuedRequest } from './rateLimiter';
import { handleFloodWait } from '../utils/floodWaitHandler';

// Old:
// await client.sendMessage(channelPeer, { message: text });

// New:
await queuedRequest(userId, async () => {
  return handleFloodWait(async () => {
    return client.sendMessage(channelPeer, { message: text });
  });
});
```

---

## ğŸ—ï¸ Distributed Architecture (50k+ Users uchun)

### **Problem:**
```
1 IP â†’ 100 userbot â†’ Har biri 30 msg/min
= 3000 requests/minute bir IPdan
= ğŸ”´ IP BLOCKED!
```

### **Solution: Multi-IP Distribution**

#### **Option 1: Proxy Rotation**
```typescript
// src/userbot/proxyManager.ts
interface ProxyConfig {
  ip: string;
  port: number;
  secret?: string;
}

const proxyPool: ProxyConfig[] = [
  { ip: '1.2.3.4', port: 443 },
  { ip: '5.6.7.8', port: 443 },
  // ... more proxies
];

export function getProxyForUser(userId: number): ProxyConfig {
  const index = userId % proxyPool.length;
  return proxyPool[index];
}

// Use when creating client:
const client = new TelegramClient(
  session,
  apiId,
  apiHash,
  {
    connectionRetries: 5,
    useWSS: false,
    proxy: getProxyForUser(userId),  // â† Different proxy per user
  }
);
```

#### **Option 2: Multiple Replit Instances**
```
Instance 1 (IP: 1.2.3.4) â†’ Users 1-1000
Instance 2 (IP: 5.6.7.8) â†’ Users 1001-2000
Instance 3 (IP: 9.10.11.12) â†’ Users 2001-3000
...
```

MongoDB bir xil bo'ladi, faqat userbot clientlar distributed.

#### **Option 3: Telegram Premium + Aged Accounts**
```
âœ… Premium subscription â†’ Higher limits
âœ… Aged accounts (2+ years) â†’ More trusted
âœ… Each account: 30 msg/min safely

50,000 users Ã· 30 msg/min = ~1667 minutes per cycle
= ~28 hours for full cycle (acceptable!)
```

---

## ğŸ“ˆ Scaling Strategy

### **Phase 1: 0-100 Users (Current)**
```
âœ… Single IP
âœ… Basic queue (25 msg/min per account)
âœ… Flood wait handling
âœ… No proxy needed
```

### **Phase 2: 100-1,000 Users**
```
âœ… Rate limiter per account
âœ… Monitoring dashboard
âœ… Alert on FLOOD_WAIT
âš ï¸ Consider proxy if >500 concurrent users
```

### **Phase 3: 1,000-10,000 Users**
```
âš ï¸ **MUST USE PROXIES or Multiple IPs**
âœ… 10 proxies â†’ 100 accounts each
âœ… Load balancer
âœ… Auto-pause on Error 429
```

### **Phase 4: 10,000-50,000 Users**
```
ğŸ”´ **DISTRIBUTED ARCHITECTURE REQUIRED**
âœ… Multiple Replit instances or VPS
âœ… 50+ proxies (MTProto proxies)
âœ… Central MongoDB
âœ… Auto-scaling based on load
âœ… Premium accounts only
```

---

## ğŸ” Monitoring & Alerts

### **Dashboard Metrics:**
```typescript
interface RateLimitMetrics {
  userId: number;
  requestsPerMinute: number;
  floodWaitCount: number;
  lastFloodWaitTime?: number;
  totalRequests: number;
  blockedUntil?: Date;
}

// Track in Redis or MongoDB
const metrics = new Map<number, RateLimitMetrics>();

// Alert if:
- FLOOD_WAIT > 1000 sekund â†’ Critical
- Error 429 â†’ STOP ALL
- Same account 3+ FLOOD_WAIT in 1 hour â†’ Pause account
```

### **Auto-Pause System:**
```typescript
// If IP blocked (Error 429):
1. Stop ALL userbot clients
2. Wait penalty time (check error message)
3. Log incident
4. Alert admin
5. Resume after penalty + 10 minutes buffer
```

---

## ğŸ›¡ï¸ Best Practices Summary

### **DO âœ…**
1. **Queue all requests** - Never direct send
2. **Respect FLOOD_WAIT** - Always sleep full duration + buffer
3. **Use aged accounts** - 2+ years old preferred
4. **Add delays** - 2-3 seconds between actions
5. **Monitor metrics** - Track FLOOD_WAIT frequency
6. **Distribute load** - Use proxies or multiple IPs for 1k+ users
7. **Premium accounts** - Higher limits, worth it for scaling
8. **Exponential backoff** - Increase delays on repeated errors

### **DON'T âŒ**
1. **Ignore errors** - Never retry immediately on FLOOD_WAIT
2. **Aggressive loops** - No tight loops without delays
3. **Same chat spam** - >1 msg/sec to same chat
4. **New accounts** - Temp SMS accounts get blocked fast
5. **Bypass limits** - Don't try to "hack" around limits
6. **Multiple connections** - Don't open many connections from 1 IP

---

## ğŸ’¡ OblivionLog Implementation Plan

### **Immediate (Now - 100 users):**
```typescript
1. âœ… Add PQueue rate limiter per user
2. âœ… Implement FLOOD_WAIT handler with retry
3. âœ… Add 2-3 second delays between archive operations
4. âœ… Log all FLOOD_WAIT incidents
```

### **Near Future (100-1000 users):**
```typescript
1. âš ï¸ Monitoring dashboard (FLOOD_WAIT frequency)
2. âš ï¸ Auto-pause accounts with repeated violations
3. âš ï¸ Alert system (Telegram notification to admin)
4. âš ï¸ Consider proxy pool if >500 users
```

### **Long Term (1000+ users):**
```typescript
1. ğŸ”´ Distributed architecture (multiple instances)
2. ğŸ”´ Proxy rotation (MTProto proxies)
3. ğŸ”´ Load balancer
4. ğŸ”´ Premium account requirement
5. ğŸ”´ Auto-scaling based on metrics
```

---

## ğŸ“Š Cost Estimate for Scaling

### **Option 1: Proxies**
```
- MTProto Proxy: $5-10/month per proxy
- 10 proxies: $50-100/month (supports 1000 users)
- 50 proxies: $250-500/month (supports 10k+ users)
```

### **Option 2: Multiple Replit Instances**
```
- Replit Core: $20/month per instance
- 5 instances: $100/month (supports 500 users each = 2500 total)
- 20 instances: $400/month (supports 10k users)
```

### **Option 3: VPS + Proxies (Best for 10k+)**
```
- VPS (8GB RAM): $40/month
- 50 MTProto proxies: $250/month
- Total: $290/month for 10k+ users
```

---

## âœ… Conclusion

**Current Status:**
- âœ… Single IP works for 100-500 users
- âœ… Basic rate limiting needed NOW
- âš ï¸ Proxies needed at 500-1000 users
- ğŸ”´ Distributed architecture needed at 5k+ users

**Immediate Action:**
1. Implement rate limiter (PQueue)
2. Add FLOOD_WAIT handler
3. Monitor metrics
4. Plan for proxy integration

**Key Takeaway:**
> IP bloklanmaydi agar to'g'ri rate limiting va queue system bo'lsa. Lekin 1000+ users uchun proxy yoki distributed architecture **SHART**!

ğŸ¯ **50k users uchun = Distributed + Proxies + Premium accounts + Monitoring**
